{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for dataLoader construction, training, and testing is largely referred from the complementary material from PyTorch course on Udacity. \n",
    "\n",
    "Link to the course: https://www.udacity.com/course/deep-learning-pytorch--ud188"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0 1 2 3]\n[0 1 2 3]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "\n",
    "print(np.unique(y_train_valid))\n",
    "print(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training/Valid data shape: (2115, 22, 1000)\nTest data shape: (443, 22, 1000)\nTraining/Valid target shape: (2115,)\nTest target shape: (443,)\nPerson train/valid shape: (2115, 1)\nPerson test shape: (443, 1)\n"
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "X_train_valid = torch.from_numpy(X_train_valid.transpose(0,2,1)).float()\n",
    "y_train_valid = torch.from_numpy(y_train_valid).long()\n",
    "train_data = data.TensorDataset(X_train_valid, y_train_valid)\n",
    "\n",
    "person_train_valid = torch.from_numpy(person_train_valid)\n",
    "person_test = torch.from_numpy(person_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is transposed so that time dimension is before the electrode dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "batch_size = 128\n",
    "valid_size = 0.2\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, drop_last=True)\n",
    "valid_loader = data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "cuda:0\nTraining on GPU ...\n"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "# check if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
    "print(device)\n",
    "if not train_on_gpu:\n",
    "    print('Training on CPU ...')\n",
    "else:\n",
    "    print('Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(RNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(22, 64, kernel_size=22, stride=2),\n",
    "            nn.BatchNorm1d(64, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=12, stride=2),\n",
    "            nn.Dropout(p=0.8),\n",
    "            nn.Conv1d(64, 192, kernel_size=12),\n",
    "            nn.BatchNorm1d(192, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Dropout(p=0.8),\n",
    "            nn.Conv1d(192, 384, kernel_size=4, stride=2),\n",
    "            nn.BatchNorm1d(384, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=1),\n",
    "        )\n",
    "        self.rnn = nn.LSTM(input_size=22, hidden_size=15, dropout=0.8, num_layers=3, batch_first = True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.BatchNorm1d(15000),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.BatchNorm1d(15000),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(15000, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        #x = self.features(x)\n",
    "        x, hidden = self.rnn(x, hidden)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the convolution layers are commented in the forward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a complete CNN\n",
    "model = RNN()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('./tensorboard/rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=0.01, lr=1e-3)\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "g Loss: 0.444252 \tValidation Loss: 1.247299\nEpoch: 4690 \tTraining Loss: 0.438310 \tValidation Loss: 1.202509\nEpoch: 4691 \tTraining Loss: 0.447957 \tValidation Loss: 1.204568\nEpoch: 4692 \tTraining Loss: 0.424285 \tValidation Loss: 1.154306\nEpoch: 4693 \tTraining Loss: 0.385227 \tValidation Loss: 1.160632\nEpoch: 4694 \tTraining Loss: 0.395918 \tValidation Loss: 1.199911\nEpoch: 4695 \tTraining Loss: 0.401770 \tValidation Loss: 1.255857\nEpoch: 4696 \tTraining Loss: 0.381088 \tValidation Loss: 1.169661\nEpoch: 4697 \tTraining Loss: 0.411731 \tValidation Loss: 1.220967\nEpoch: 4698 \tTraining Loss: 0.427690 \tValidation Loss: 1.224593\nEpoch: 4699 \tTraining Loss: 0.939139 \tValidation Loss: 1.305815\nEpoch: 4700 \tTraining Loss: 1.034862 \tValidation Loss: 1.168285\nEpoch: 4701 \tTraining Loss: 0.888939 \tValidation Loss: 1.094032\nEpoch: 4702 \tTraining Loss: 0.824923 \tValidation Loss: 1.068267\nEpoch: 4703 \tTraining Loss: 0.786585 \tValidation Loss: 1.159292\nEpoch: 4704 \tTraining Loss: 0.710284 \tValidation Loss: 1.052108\nEpoch: 4705 \tTraining Loss: 0.696411 \tValidation Loss: 1.083711\nEpoch: 4706 \tTraining Loss: 0.666934 \tValidation Loss: 1.079836\nEpoch: 4707 \tTraining Loss: 0.659771 \tValidation Loss: 1.095061\nEpoch: 4708 \tTraining Loss: 0.640418 \tValidation Loss: 1.100904\nEpoch: 4709 \tTraining Loss: 0.614648 \tValidation Loss: 1.126697\nEpoch: 4710 \tTraining Loss: 0.598584 \tValidation Loss: 1.109566\nEpoch: 4711 \tTraining Loss: 0.600583 \tValidation Loss: 1.065306\nEpoch: 4712 \tTraining Loss: 0.574628 \tValidation Loss: 1.105549\nEpoch: 4713 \tTraining Loss: 0.591674 \tValidation Loss: 1.110683\nEpoch: 4714 \tTraining Loss: 0.564467 \tValidation Loss: 1.100203\nEpoch: 4715 \tTraining Loss: 0.561012 \tValidation Loss: 1.133189\nEpoch: 4716 \tTraining Loss: 0.556861 \tValidation Loss: 1.160730\nEpoch: 4717 \tTraining Loss: 0.554047 \tValidation Loss: 1.155705\nEpoch: 4718 \tTraining Loss: 0.533027 \tValidation Loss: 1.163241\nEpoch: 4719 \tTraining Loss: 0.506181 \tValidation Loss: 1.148326\nEpoch: 4720 \tTraining Loss: 0.512034 \tValidation Loss: 1.191871\nEpoch: 4721 \tTraining Loss: 0.514834 \tValidation Loss: 1.196224\nEpoch: 4722 \tTraining Loss: 0.475963 \tValidation Loss: 1.200492\nEpoch: 4723 \tTraining Loss: 0.464608 \tValidation Loss: 1.236582\nEpoch: 4724 \tTraining Loss: 0.465950 \tValidation Loss: 1.131972\nEpoch: 4725 \tTraining Loss: 0.483721 \tValidation Loss: 1.158431\nEpoch: 4726 \tTraining Loss: 0.484624 \tValidation Loss: 1.208412\nEpoch: 4727 \tTraining Loss: 0.480844 \tValidation Loss: 1.208682\nEpoch: 4728 \tTraining Loss: 0.475190 \tValidation Loss: 1.251912\nEpoch: 4729 \tTraining Loss: 0.478813 \tValidation Loss: 1.189085\nEpoch: 4730 \tTraining Loss: 0.457917 \tValidation Loss: 1.210876\nEpoch: 4731 \tTraining Loss: 0.459477 \tValidation Loss: 1.192248\nEpoch: 4732 \tTraining Loss: 0.455976 \tValidation Loss: 1.188458\nEpoch: 4733 \tTraining Loss: 0.439520 \tValidation Loss: 1.168864\nEpoch: 4734 \tTraining Loss: 0.430927 \tValidation Loss: 1.184663\nEpoch: 4735 \tTraining Loss: 0.408513 \tValidation Loss: 1.213326\nEpoch: 4736 \tTraining Loss: 0.427596 \tValidation Loss: 1.273003\nEpoch: 4737 \tTraining Loss: 0.458829 \tValidation Loss: 1.195495\nEpoch: 4738 \tTraining Loss: 0.448411 \tValidation Loss: 1.226307\nEpoch: 4739 \tTraining Loss: 0.452915 \tValidation Loss: 1.261406\nEpoch: 4740 \tTraining Loss: 0.448939 \tValidation Loss: 1.231313\nEpoch: 4741 \tTraining Loss: 0.408727 \tValidation Loss: 1.198888\nEpoch: 4742 \tTraining Loss: 0.415405 \tValidation Loss: 1.224078\nEpoch: 4743 \tTraining Loss: 0.392987 \tValidation Loss: 1.191601\nEpoch: 4744 \tTraining Loss: 0.398339 \tValidation Loss: 1.188739\nEpoch: 4745 \tTraining Loss: 0.402862 \tValidation Loss: 1.212651\nEpoch: 4746 \tTraining Loss: 0.417204 \tValidation Loss: 1.240849\nEpoch: 4747 \tTraining Loss: 0.424145 \tValidation Loss: 1.310313\nEpoch: 4748 \tTraining Loss: 0.409226 \tValidation Loss: 1.291727\nEpoch: 4749 \tTraining Loss: 0.395916 \tValidation Loss: 1.199560\nEpoch: 4750 \tTraining Loss: 0.411497 \tValidation Loss: 1.239031\nEpoch: 4751 \tTraining Loss: 0.381204 \tValidation Loss: 1.267037\nEpoch: 4752 \tTraining Loss: 0.380389 \tValidation Loss: 1.213692\nEpoch: 4753 \tTraining Loss: 0.402600 \tValidation Loss: 1.186428\nEpoch: 4754 \tTraining Loss: 0.391153 \tValidation Loss: 1.243528\nEpoch: 4755 \tTraining Loss: 0.388054 \tValidation Loss: 1.203958\nEpoch: 4756 \tTraining Loss: 0.401311 \tValidation Loss: 1.306700\nEpoch: 4757 \tTraining Loss: 0.384838 \tValidation Loss: 1.286782\nEpoch: 4758 \tTraining Loss: 0.378615 \tValidation Loss: 1.260644\nEpoch: 4759 \tTraining Loss: 0.368609 \tValidation Loss: 1.264560\nEpoch: 4760 \tTraining Loss: 0.376951 \tValidation Loss: 1.224506\nEpoch: 4761 \tTraining Loss: 0.378496 \tValidation Loss: 1.253198\nEpoch: 4762 \tTraining Loss: 0.418540 \tValidation Loss: 1.198546\nEpoch: 4763 \tTraining Loss: 0.439368 \tValidation Loss: 1.267724\nEpoch: 4764 \tTraining Loss: 0.410197 \tValidation Loss: 1.193497\nEpoch: 4765 \tTraining Loss: 0.395488 \tValidation Loss: 1.219845\nEpoch: 4766 \tTraining Loss: 0.397721 \tValidation Loss: 1.219236\nEpoch: 4767 \tTraining Loss: 0.391839 \tValidation Loss: 1.211472\nEpoch: 4768 \tTraining Loss: 0.375826 \tValidation Loss: 1.210690\nEpoch: 4769 \tTraining Loss: 0.369846 \tValidation Loss: 1.197427\nEpoch: 4770 \tTraining Loss: 0.386476 \tValidation Loss: 1.232533\nEpoch: 4771 \tTraining Loss: 0.387833 \tValidation Loss: 1.199154\nEpoch: 4772 \tTraining Loss: 0.405222 \tValidation Loss: 1.235776\nEpoch: 4773 \tTraining Loss: 0.390334 \tValidation Loss: 1.244685\nEpoch: 4774 \tTraining Loss: 0.683315 \tValidation Loss: 1.164274\nEpoch: 4775 \tTraining Loss: 0.603993 \tValidation Loss: 1.135826\nEpoch: 4776 \tTraining Loss: 0.502656 \tValidation Loss: 1.132182\nEpoch: 4777 \tTraining Loss: 0.478270 \tValidation Loss: 1.206194\nEpoch: 4778 \tTraining Loss: 0.421710 \tValidation Loss: 1.166547\nEpoch: 4779 \tTraining Loss: 0.428775 \tValidation Loss: 1.126329\nEpoch: 4780 \tTraining Loss: 0.409915 \tValidation Loss: 1.218100\nEpoch: 4781 \tTraining Loss: 0.401111 \tValidation Loss: 1.239637\nEpoch: 4782 \tTraining Loss: 0.398664 \tValidation Loss: 1.167246\nEpoch: 4783 \tTraining Loss: 0.413925 \tValidation Loss: 1.220894\nEpoch: 4784 \tTraining Loss: 0.428962 \tValidation Loss: 1.229218\nEpoch: 4785 \tTraining Loss: 0.396374 \tValidation Loss: 1.314111\nEpoch: 4786 \tTraining Loss: 0.507805 \tValidation Loss: 1.278846\nEpoch: 4787 \tTraining Loss: 0.499799 \tValidation Loss: 1.215209\nEpoch: 4788 \tTraining Loss: 0.470998 \tValidation Loss: 1.273380\nEpoch: 4789 \tTraining Loss: 0.454805 \tValidation Loss: 1.252452\nEpoch: 4790 \tTraining Loss: 0.413121 \tValidation Loss: 1.167883\nEpoch: 4791 \tTraining Loss: 0.419510 \tValidation Loss: 1.202379\nEpoch: 4792 \tTraining Loss: 0.413032 \tValidation Loss: 1.175020\nEpoch: 4793 \tTraining Loss: 0.391913 \tValidation Loss: 1.202099\nEpoch: 4794 \tTraining Loss: 0.370751 \tValidation Loss: 1.241672\nEpoch: 4795 \tTraining Loss: 0.385354 \tValidation Loss: 1.269955\nEpoch: 4796 \tTraining Loss: 0.488895 \tValidation Loss: 1.186433\nEpoch: 4797 \tTraining Loss: 0.502187 \tValidation Loss: 1.183994\nEpoch: 4798 \tTraining Loss: 0.466030 \tValidation Loss: 1.154830\nEpoch: 4799 \tTraining Loss: 0.414382 \tValidation Loss: 1.179468\nEpoch: 4800 \tTraining Loss: 0.407798 \tValidation Loss: 1.208776\nEpoch: 4801 \tTraining Loss: 0.358092 \tValidation Loss: 1.226936\nEpoch: 4802 \tTraining Loss: 0.365052 \tValidation Loss: 1.275235\nEpoch: 4803 \tTraining Loss: 0.419308 \tValidation Loss: 1.282508\nEpoch: 4804 \tTraining Loss: 0.464163 \tValidation Loss: 1.223139\nEpoch: 4805 \tTraining Loss: 0.442612 \tValidation Loss: 1.180662\nEpoch: 4806 \tTraining Loss: 0.411479 \tValidation Loss: 1.191249\nEpoch: 4807 \tTraining Loss: 0.397649 \tValidation Loss: 1.157629\nEpoch: 4808 \tTraining Loss: 0.439496 \tValidation Loss: 1.210523\nEpoch: 4809 \tTraining Loss: 0.424381 \tValidation Loss: 1.195095\nEpoch: 4810 \tTraining Loss: 0.389360 \tValidation Loss: 1.131212\nEpoch: 4811 \tTraining Loss: 0.397182 \tValidation Loss: 1.296587\nEpoch: 4812 \tTraining Loss: 0.418205 \tValidation Loss: 1.302677\nEpoch: 4813 \tTraining Loss: 0.411216 \tValidation Loss: 1.162905\nEpoch: 4814 \tTraining Loss: 0.376271 \tValidation Loss: 1.222100\nEpoch: 4815 \tTraining Loss: 0.399392 \tValidation Loss: 1.258109\nEpoch: 4816 \tTraining Loss: 0.413747 \tValidation Loss: 1.286602\nEpoch: 4817 \tTraining Loss: 0.392713 \tValidation Loss: 1.198124\nEpoch: 4818 \tTraining Loss: 0.387917 \tValidation Loss: 1.291013\nEpoch: 4819 \tTraining Loss: 0.379218 \tValidation Loss: 1.228502\nEpoch: 4820 \tTraining Loss: 0.381226 \tValidation Loss: 1.218457\nEpoch: 4821 \tTraining Loss: 0.381712 \tValidation Loss: 1.180352\nEpoch: 4822 \tTraining Loss: 0.374337 \tValidation Loss: 1.231258\nEpoch: 4823 \tTraining Loss: 0.380742 \tValidation Loss: 1.252256\nEpoch: 4824 \tTraining Loss: 0.385364 \tValidation Loss: 1.240104\nEpoch: 4825 \tTraining Loss: 0.356405 \tValidation Loss: 1.271487\nEpoch: 4826 \tTraining Loss: 0.378100 \tValidation Loss: 1.243896\nEpoch: 4827 \tTraining Loss: 0.368166 \tValidation Loss: 1.317560\nEpoch: 4828 \tTraining Loss: 0.382576 \tValidation Loss: 1.222492\nEpoch: 4829 \tTraining Loss: 0.383568 \tValidation Loss: 1.212242\nEpoch: 4830 \tTraining Loss: 0.371230 \tValidation Loss: 1.180600\nEpoch: 4831 \tTraining Loss: 0.410869 \tValidation Loss: 1.191960\nEpoch: 4832 \tTraining Loss: 0.415069 \tValidation Loss: 1.177177\nEpoch: 4833 \tTraining Loss: 0.402401 \tValidation Loss: 1.239740\nEpoch: 4834 \tTraining Loss: 0.377015 \tValidation Loss: 1.233003\nEpoch: 4835 \tTraining Loss: 0.404390 \tValidation Loss: 1.229968\nEpoch: 4836 \tTraining Loss: 0.403982 \tValidation Loss: 1.199515\nEpoch: 4837 \tTraining Loss: 0.429674 \tValidation Loss: 1.312046\nEpoch: 4838 \tTraining Loss: 0.403627 \tValidation Loss: 1.221170\nEpoch: 4839 \tTraining Loss: 0.394961 \tValidation Loss: 1.234928\nEpoch: 4840 \tTraining Loss: 0.387170 \tValidation Loss: 1.311517\nEpoch: 4841 \tTraining Loss: 0.392646 \tValidation Loss: 1.218038\nEpoch: 4842 \tTraining Loss: 0.376990 \tValidation Loss: 1.311532\nEpoch: 4843 \tTraining Loss: 0.374428 \tValidation Loss: 1.218405\nEpoch: 4844 \tTraining Loss: 0.360622 \tValidation Loss: 1.283225\nEpoch: 4845 \tTraining Loss: 0.376877 \tValidation Loss: 1.236114\nEpoch: 4846 \tTraining Loss: 0.522471 \tValidation Loss: 1.223526\nEpoch: 4847 \tTraining Loss: 0.614647 \tValidation Loss: 1.135557\nEpoch: 4848 \tTraining Loss: 0.552273 \tValidation Loss: 1.159960\nEpoch: 4849 \tTraining Loss: 0.500424 \tValidation Loss: 1.195608\nEpoch: 4850 \tTraining Loss: 0.458919 \tValidation Loss: 1.167846\nEpoch: 4851 \tTraining Loss: 0.441635 \tValidation Loss: 1.173769\nEpoch: 4852 \tTraining Loss: 0.421652 \tValidation Loss: 1.204204\nEpoch: 4853 \tTraining Loss: 0.404088 \tValidation Loss: 1.272821\nEpoch: 4854 \tTraining Loss: 0.386519 \tValidation Loss: 1.235173\nEpoch: 4855 \tTraining Loss: 0.407705 \tValidation Loss: 1.231812\nEpoch: 4856 \tTraining Loss: 0.394817 \tValidation Loss: 1.193014\nEpoch: 4857 \tTraining Loss: 0.383249 \tValidation Loss: 1.173435\nEpoch: 4858 \tTraining Loss: 0.398256 \tValidation Loss: 1.248611\nEpoch: 4859 \tTraining Loss: 0.400826 \tValidation Loss: 1.268284\nEpoch: 4860 \tTraining Loss: 0.410559 \tValidation Loss: 1.147849\nEpoch: 4861 \tTraining Loss: 0.408310 \tValidation Loss: 1.207613\nEpoch: 4862 \tTraining Loss: 0.389373 \tValidation Loss: 1.194275\nEpoch: 4863 \tTraining Loss: 0.386111 \tValidation Loss: 1.265924\nEpoch: 4864 \tTraining Loss: 0.439575 \tValidation Loss: 1.238203\nEpoch: 4865 \tTraining Loss: 0.394684 \tValidation Loss: 1.235607\nEpoch: 4866 \tTraining Loss: 0.379956 \tValidation Loss: 1.181845\nEpoch: 4867 \tTraining Loss: 0.399150 \tValidation Loss: 1.209431\nEpoch: 4868 \tTraining Loss: 0.390345 \tValidation Loss: 1.262206\nEpoch: 4869 \tTraining Loss: 0.401826 \tValidation Loss: 1.374476\nEpoch: 4870 \tTraining Loss: 0.399985 \tValidation Loss: 1.265570\nEpoch: 4871 \tTraining Loss: 0.434867 \tValidation Loss: 1.258283\nEpoch: 4872 \tTraining Loss: 0.379901 \tValidation Loss: 1.289736\nEpoch: 4873 \tTraining Loss: 0.375217 \tValidation Loss: 1.258079\nEpoch: 4874 \tTraining Loss: 0.368852 \tValidation Loss: 1.244846\nEpoch: 4875 \tTraining Loss: 0.357561 \tValidation Loss: 1.230981\nEpoch: 4876 \tTraining Loss: 0.398299 \tValidation Loss: 1.257427\nEpoch: 4877 \tTraining Loss: 0.445182 \tValidation Loss: 1.240227\nEpoch: 4878 \tTraining Loss: 0.394756 \tValidation Loss: 1.250214\nEpoch: 4879 \tTraining Loss: 0.401991 \tValidation Loss: 1.204519\nEpoch: 4880 \tTraining Loss: 0.373746 \tValidation Loss: 1.294162\nEpoch: 4881 \tTraining Loss: 0.387722 \tValidation Loss: 1.202740\nEpoch: 4882 \tTraining Loss: 0.373767 \tValidation Loss: 1.163754\nEpoch: 4883 \tTraining Loss: 0.377502 \tValidation Loss: 1.169113\nEpoch: 4884 \tTraining Loss: 0.369693 \tValidation Loss: 1.246504\nEpoch: 4885 \tTraining Loss: 0.378430 \tValidation Loss: 1.371551\nEpoch: 4886 \tTraining Loss: 0.387873 \tValidation Loss: 1.236415\nEpoch: 4887 \tTraining Loss: 0.389788 \tValidation Loss: 1.186263\nEpoch: 4888 \tTraining Loss: 0.458595 \tValidation Loss: 1.269186\nEpoch: 4889 \tTraining Loss: 0.446460 \tValidation Loss: 1.225179\nEpoch: 4890 \tTraining Loss: 0.426930 \tValidation Loss: 1.198775\nEpoch: 4891 \tTraining Loss: 0.461257 \tValidation Loss: 1.217426\nEpoch: 4892 \tTraining Loss: 0.423438 \tValidation Loss: 1.334828\nEpoch: 4893 \tTraining Loss: 0.390864 \tValidation Loss: 1.249928\nEpoch: 4894 \tTraining Loss: 0.380830 \tValidation Loss: 1.225615\nEpoch: 4895 \tTraining Loss: 0.390639 \tValidation Loss: 1.274188\nEpoch: 4896 \tTraining Loss: 0.409427 \tValidation Loss: 1.197408\nEpoch: 4897 \tTraining Loss: 0.405791 \tValidation Loss: 1.237632\nEpoch: 4898 \tTraining Loss: 0.385205 \tValidation Loss: 1.325024\nEpoch: 4899 \tTraining Loss: 0.383365 \tValidation Loss: 1.201672\nEpoch: 4900 \tTraining Loss: 0.382108 \tValidation Loss: 1.290972\nEpoch: 4901 \tTraining Loss: 0.380147 \tValidation Loss: 1.221993\nEpoch: 4902 \tTraining Loss: 0.364680 \tValidation Loss: 1.256841\nEpoch: 4903 \tTraining Loss: 0.365123 \tValidation Loss: 1.220934\nEpoch: 4904 \tTraining Loss: 0.348282 \tValidation Loss: 1.237361\nEpoch: 4905 \tTraining Loss: 0.349172 \tValidation Loss: 1.211173\nEpoch: 4906 \tTraining Loss: 0.381629 \tValidation Loss: 1.217594\nEpoch: 4907 \tTraining Loss: 0.404561 \tValidation Loss: 1.238374\nEpoch: 4908 \tTraining Loss: 0.396631 \tValidation Loss: 1.207318\nEpoch: 4909 \tTraining Loss: 0.394090 \tValidation Loss: 1.252402\nEpoch: 4910 \tTraining Loss: 0.418188 \tValidation Loss: 1.324614\nEpoch: 4911 \tTraining Loss: 0.420525 \tValidation Loss: 1.281303\nEpoch: 4912 \tTraining Loss: 0.397876 \tValidation Loss: 1.182885\nEpoch: 4913 \tTraining Loss: 0.411556 \tValidation Loss: 1.141822\nEpoch: 4914 \tTraining Loss: 0.401349 \tValidation Loss: 1.235728\nEpoch: 4915 \tTraining Loss: 0.373740 \tValidation Loss: 1.216237\nEpoch: 4916 \tTraining Loss: 0.367993 \tValidation Loss: 1.221298\nEpoch: 4917 \tTraining Loss: 0.397403 \tValidation Loss: 1.299519\nEpoch: 4918 \tTraining Loss: 0.385584 \tValidation Loss: 1.299751\nEpoch: 4919 \tTraining Loss: 0.403449 \tValidation Loss: 1.243593\nEpoch: 4920 \tTraining Loss: 0.410655 \tValidation Loss: 1.186173\nEpoch: 4921 \tTraining Loss: 0.399743 \tValidation Loss: 1.192096\nEpoch: 4922 \tTraining Loss: 0.370862 \tValidation Loss: 1.173268\nEpoch: 4923 \tTraining Loss: 0.401655 \tValidation Loss: 1.290818\nEpoch: 4924 \tTraining Loss: 0.641310 \tValidation Loss: 1.184676\nEpoch: 4925 \tTraining Loss: 0.537845 \tValidation Loss: 1.202185\nEpoch: 4926 \tTraining Loss: 0.511301 \tValidation Loss: 1.258075\nEpoch: 4927 \tTraining Loss: 0.485075 \tValidation Loss: 1.218009\nEpoch: 4928 \tTraining Loss: 0.459584 \tValidation Loss: 1.188891\nEpoch: 4929 \tTraining Loss: 0.449380 \tValidation Loss: 1.183330\nEpoch: 4930 \tTraining Loss: 0.418478 \tValidation Loss: 1.188333\nEpoch: 4931 \tTraining Loss: 0.405834 \tValidation Loss: 1.197776\nEpoch: 4932 \tTraining Loss: 0.380564 \tValidation Loss: 1.304455\nEpoch: 4933 \tTraining Loss: 0.390047 \tValidation Loss: 1.236264\nEpoch: 4934 \tTraining Loss: 0.358236 \tValidation Loss: 1.272390\nEpoch: 4935 \tTraining Loss: 0.370177 \tValidation Loss: 1.331687\nEpoch: 4936 \tTraining Loss: 0.378411 \tValidation Loss: 1.235893\nEpoch: 4937 \tTraining Loss: 0.390817 \tValidation Loss: 1.236414\nEpoch: 4938 \tTraining Loss: 0.491926 \tValidation Loss: 1.283667\nEpoch: 4939 \tTraining Loss: 0.475427 \tValidation Loss: 1.207334\nEpoch: 4940 \tTraining Loss: 0.442349 \tValidation Loss: 1.151229\nEpoch: 4941 \tTraining Loss: 0.429432 \tValidation Loss: 1.173352\nEpoch: 4942 \tTraining Loss: 0.437586 \tValidation Loss: 1.251338\nEpoch: 4943 \tTraining Loss: 0.427771 \tValidation Loss: 1.195691\nEpoch: 4944 \tTraining Loss: 0.383751 \tValidation Loss: 1.202045\nEpoch: 4945 \tTraining Loss: 0.384706 \tValidation Loss: 1.225106\nEpoch: 4946 \tTraining Loss: 0.371591 \tValidation Loss: 1.221426\nEpoch: 4947 \tTraining Loss: 0.356443 \tValidation Loss: 1.165929\nEpoch: 4948 \tTraining Loss: 0.388360 \tValidation Loss: 1.192913\nEpoch: 4949 \tTraining Loss: 0.381320 \tValidation Loss: 1.243336\nEpoch: 4950 \tTraining Loss: 0.387564 \tValidation Loss: 1.244900\nEpoch: 4951 \tTraining Loss: 0.373755 \tValidation Loss: 1.268558\nEpoch: 4952 \tTraining Loss: 0.381784 \tValidation Loss: 1.288370\nEpoch: 4953 \tTraining Loss: 0.355402 \tValidation Loss: 1.221086\nEpoch: 4954 \tTraining Loss: 0.375378 \tValidation Loss: 1.229213\nEpoch: 4955 \tTraining Loss: 0.370419 \tValidation Loss: 1.264052\nEpoch: 4956 \tTraining Loss: 0.373753 \tValidation Loss: 1.231573\nEpoch: 4957 \tTraining Loss: 0.382112 \tValidation Loss: 1.199658\nEpoch: 4958 \tTraining Loss: 0.418897 \tValidation Loss: 1.267938\nEpoch: 4959 \tTraining Loss: 0.621809 \tValidation Loss: 1.240937\nEpoch: 4960 \tTraining Loss: 0.576556 \tValidation Loss: 1.205495\nEpoch: 4961 \tTraining Loss: 0.512496 \tValidation Loss: 1.102933\nEpoch: 4962 \tTraining Loss: 0.508310 \tValidation Loss: 1.143045\nEpoch: 4963 \tTraining Loss: 0.487241 \tValidation Loss: 1.145063\nEpoch: 4964 \tTraining Loss: 0.450218 \tValidation Loss: 1.249340\nEpoch: 4965 \tTraining Loss: 0.563389 \tValidation Loss: 1.124380\nEpoch: 4966 \tTraining Loss: 0.508452 \tValidation Loss: 1.175680\nEpoch: 4967 \tTraining Loss: 0.465558 \tValidation Loss: 1.194636\nEpoch: 4968 \tTraining Loss: 0.443652 \tValidation Loss: 1.155554\nEpoch: 4969 \tTraining Loss: 0.448441 \tValidation Loss: 1.161499\nEpoch: 4970 \tTraining Loss: 0.428174 \tValidation Loss: 1.242797\nEpoch: 4971 \tTraining Loss: 0.411885 \tValidation Loss: 1.224876\nEpoch: 4972 \tTraining Loss: 0.398593 \tValidation Loss: 1.288015\nEpoch: 4973 \tTraining Loss: 0.373655 \tValidation Loss: 1.284189\nEpoch: 4974 \tTraining Loss: 0.391011 \tValidation Loss: 1.245612\nEpoch: 4975 \tTraining Loss: 0.405513 \tValidation Loss: 1.248070\nEpoch: 4976 \tTraining Loss: 0.466226 \tValidation Loss: 1.208423\nEpoch: 4977 \tTraining Loss: 0.419079 \tValidation Loss: 1.131687\nEpoch: 4978 \tTraining Loss: 0.419593 \tValidation Loss: 1.239389\nEpoch: 4979 \tTraining Loss: 0.388753 \tValidation Loss: 1.276258\nEpoch: 4980 \tTraining Loss: 0.417777 \tValidation Loss: 1.294549\nEpoch: 4981 \tTraining Loss: 0.464617 \tValidation Loss: 1.333937\nEpoch: 4982 \tTraining Loss: 0.433426 \tValidation Loss: 1.202424\nEpoch: 4983 \tTraining Loss: 0.451844 \tValidation Loss: 1.155776\nEpoch: 4984 \tTraining Loss: 0.463642 \tValidation Loss: 1.169498\nEpoch: 4985 \tTraining Loss: 0.474016 \tValidation Loss: 1.241943\nEpoch: 4986 \tTraining Loss: 0.472396 \tValidation Loss: 1.149812\nEpoch: 4987 \tTraining Loss: 0.410101 \tValidation Loss: 1.164552\nEpoch: 4988 \tTraining Loss: 0.399842 \tValidation Loss: 1.149589\nEpoch: 4989 \tTraining Loss: 0.378560 \tValidation Loss: 1.182103\nEpoch: 4990 \tTraining Loss: 0.373660 \tValidation Loss: 1.209663\nEpoch: 4991 \tTraining Loss: 0.375655 \tValidation Loss: 1.243571\nEpoch: 4992 \tTraining Loss: 0.405512 \tValidation Loss: 1.274349\nEpoch: 4993 \tTraining Loss: 0.419847 \tValidation Loss: 1.205608\nEpoch: 4994 \tTraining Loss: 0.417855 \tValidation Loss: 1.178939\nEpoch: 4995 \tTraining Loss: 0.398774 \tValidation Loss: 1.188850\nEpoch: 4996 \tTraining Loss: 0.407659 \tValidation Loss: 1.239162\nEpoch: 4997 \tTraining Loss: 0.402869 \tValidation Loss: 1.225229\nEpoch: 4998 \tTraining Loss: 0.395172 \tValidation Loss: 1.252560\nEpoch: 4999 \tTraining Loss: 0.406964 \tValidation Loss: 1.230747\nEpoch: 5000 \tTraining Loss: 0.485460 \tValidation Loss: 1.203348\nTotal time: 8153.412, average time per epoch: 1.631\n"
    }
   ],
   "source": [
    "import time\n",
    "# number of epochs to train the model\n",
    "n_epochs = 5000\n",
    "t0 = time.time()\n",
    "\n",
    "hidden=None\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model(data, hidden)\n",
    "        a, b = hidden\n",
    "        hidden = (a.data, b.data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output, _ = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    writer.add_scalar('Train/Loss', train_loss, epoch)\n",
    "    writer.add_scalar('Valid/Loss', loss, epoch)\n",
    "\n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_EEG.pt')\n",
    "\n",
    "time_total = time.time() - t0\n",
    "print('Total time: {:4.3f}, average time per epoch: {:4.3f}'.format(time_total, time_total / n_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the Model with the Lowest Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_EEG.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the Trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "X_test = torch.from_numpy(X_test.transpose(0,2,1)).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "test_data = data.TensorDataset(X_test, y_test)\n",
    "\n",
    "test_loader = data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Test Loss: 0.987191\n\nTest Accuracy of   769: 65% (73/111)\nTest Accuracy of   770: 51% (65/127)\nTest Accuracy of   771: 50% (48/96)\nTest Accuracy of   772: 69% (76/109)\n\nTest Accuracy (Overall): 59% (262/443)\n"
    }
   ],
   "source": [
    "# specify the target classes\n",
    "classes = [769, 770, 771, 772]\n",
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "\n",
    "model.eval()\n",
    "for data, target in test_loader:\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    output, _ = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    #print(pred)\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(correct.shape[0]):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(4):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}