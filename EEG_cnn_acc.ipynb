{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0 1 2 3]\n[0 1 2 3]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "\n",
    "\n",
    "print(np.unique(y_train_valid))\n",
    "print(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training/Valid data shape: (2115, 22, 1000)\nTest data shape: (443, 22, 1000)\nTraining/Valid target shape: (2115,)\nTest target shape: (443,)\nPerson train/valid shape: (2115, 1)\nPerson test shape: (443, 1)\n"
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "X_train_valid = torch.from_numpy(X_train_valid).float()\n",
    "y_train_valid = torch.from_numpy(y_train_valid).long()\n",
    "train_data = data.TensorDataset(X_train_valid, y_train_valid)\n",
    "\n",
    "person_train_valid = torch.from_numpy(person_train_valid)\n",
    "person_test = torch.from_numpy(person_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "batch_size = 128\n",
    "valid_size = 0.2\n",
    "\n",
    "\"\"\"\n",
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\"\"\"\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet (modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "cuda:0\nTraining on GPU ...\n"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "# check if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
    "print(device)\n",
    "if not train_on_gpu:\n",
    "    print('Training on CPU ...')\n",
    "else:\n",
    "    print('Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(22, 64, kernel_size=22, stride=2),\n",
    "            nn.BatchNorm1d(64, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=12, stride=2),\n",
    "            nn.Dropout(p=0.8),\n",
    "            nn.Conv1d(64, 192, kernel_size=12),\n",
    "            nn.BatchNorm1d(192, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=2),\n",
    "            nn.Dropout(p=0.8),\n",
    "            nn.Conv1d(192, 384, kernel_size=4, stride=2),\n",
    "            nn.BatchNorm1d(384, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=0.8),\n",
    "            nn.Conv1d(384, 256, kernel_size=4, stride=2),\n",
    "            nn.BatchNorm1d(256, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=0.8),\n",
    "            nn.Conv1d(256, 256, kernel_size=4),\n",
    "            nn.BatchNorm1d(256, affine=False),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=1),\n",
    "            \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.BatchNorm1d(256 * 21),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256 * 21),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(256 * 21, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# create a complete CNN\n",
    "model = AlexNet()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=0.0005, lr=1e-3)\n",
    "\n",
    "#valid_loss_min = np.Inf # track change in validation loss\n",
    "val_acc_max = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": " Train Loss: 0.3566  Val Loss: 1.0907  Train Acc: 0.854019 Val Acc: 0.557920\nEpoch1772  Train Loss: 0.3655  Val Loss: 1.1971  Train Acc: 0.864657 Val Acc: 0.508274\nEpoch1773  Train Loss: 0.3790  Val Loss: 1.0986  Train Acc: 0.849882 Val Acc: 0.550827\nEpoch1774  Train Loss: 0.3926  Val Loss: 1.0914  Train Acc: 0.851655 Val Acc: 0.569740\nEpoch1775  Train Loss: 0.4199  Val Loss: 1.2001  Train Acc: 0.841017 Val Acc: 0.513002\nEpoch1776  Train Loss: 0.3871  Val Loss: 1.1302  Train Acc: 0.848109 Val Acc: 0.553191\nEpoch1777  Train Loss: 0.3738  Val Loss: 1.2464  Train Acc: 0.854610 Val Acc: 0.482270\nEpoch1778  Train Loss: 0.3525  Val Loss: 1.0053  Train Acc: 0.858156 Val Acc: 0.593381\nEpoch1779  Train Loss: 0.3636  Val Loss: 1.3266  Train Acc: 0.851064 Val Acc: 0.486998\nEpoch1780  Train Loss: 0.3781  Val Loss: 0.9999  Train Acc: 0.850473 Val Acc: 0.602837\nEpoch1781  Train Loss: 0.3894  Val Loss: 1.1355  Train Acc: 0.849882 Val Acc: 0.534279\nEpoch1782  Train Loss: 0.3666  Val Loss: 1.1200  Train Acc: 0.871749 Val Acc: 0.522459\nEpoch1783  Train Loss: 0.3904  Val Loss: 1.3685  Train Acc: 0.849291 Val Acc: 0.465721\nEpoch1784  Train Loss: 0.3926  Val Loss: 1.0933  Train Acc: 0.849882 Val Acc: 0.562648\nEpoch1785  Train Loss: 0.3852  Val Loss: 1.0685  Train Acc: 0.860520 Val Acc: 0.553191\nEpoch1786  Train Loss: 0.3750  Val Loss: 1.1041  Train Acc: 0.860520 Val Acc: 0.541371\nEpoch1787  Train Loss: 0.3718  Val Loss: 1.2606  Train Acc: 0.859929 Val Acc: 0.494090\nEpoch1788  Train Loss: 0.3943  Val Loss: 1.1335  Train Acc: 0.848700 Val Acc: 0.531915\nEpoch1789  Train Loss: 0.3926  Val Loss: 1.2105  Train Acc: 0.849291 Val Acc: 0.486998\nEpoch1790  Train Loss: 0.4134  Val Loss: 1.1048  Train Acc: 0.847518 Val Acc: 0.553191\nEpoch1791  Train Loss: 0.3949  Val Loss: 1.1384  Train Acc: 0.846927 Val Acc: 0.539007\nEpoch1792  Train Loss: 0.3945  Val Loss: 0.9684  Train Acc: 0.843381 Val Acc: 0.614657\nEpoch1793  Train Loss: 0.4017  Val Loss: 1.0612  Train Acc: 0.845154 Val Acc: 0.576832\nEpoch1794  Train Loss: 0.3768  Val Loss: 1.1767  Train Acc: 0.858747 Val Acc: 0.513002\nEpoch1795  Train Loss: 0.3959  Val Loss: 0.9546  Train Acc: 0.849882 Val Acc: 0.609929\nEpoch1796  Train Loss: 0.4069  Val Loss: 1.0575  Train Acc: 0.847518 Val Acc: 0.569740\nEpoch1797  Train Loss: 0.3694  Val Loss: 1.0809  Train Acc: 0.856383 Val Acc: 0.550827\nEpoch1798  Train Loss: 0.3841  Val Loss: 1.1163  Train Acc: 0.858747 Val Acc: 0.536643\nEpoch1799  Train Loss: 0.4002  Val Loss: 0.9823  Train Acc: 0.843381 Val Acc: 0.605201\nEpoch1800  Train Loss: 0.4118  Val Loss: 1.0453  Train Acc: 0.851064 Val Acc: 0.579196\nEpoch1801  Train Loss: 0.3827  Val Loss: 1.1327  Train Acc: 0.846336 Val Acc: 0.534279\nEpoch1802  Train Loss: 0.3676  Val Loss: 1.0283  Train Acc: 0.858156 Val Acc: 0.595745\nEpoch1803  Train Loss: 0.3929  Val Loss: 1.1767  Train Acc: 0.849291 Val Acc: 0.520095\nEpoch1804  Train Loss: 0.3837  Val Loss: 1.0691  Train Acc: 0.858156 Val Acc: 0.557920\nEpoch1805  Train Loss: 0.3708  Val Loss: 1.3094  Train Acc: 0.861702 Val Acc: 0.479905\nEpoch1806  Train Loss: 0.3766  Val Loss: 1.0790  Train Acc: 0.851064 Val Acc: 0.562648\nEpoch1807  Train Loss: 0.4041  Val Loss: 1.0229  Train Acc: 0.845745 Val Acc: 0.572104\nEpoch1808  Train Loss: 0.3977  Val Loss: 1.1325  Train Acc: 0.854019 Val Acc: 0.565012\nEpoch1809  Train Loss: 0.4291  Val Loss: 1.1450  Train Acc: 0.837470 Val Acc: 0.553191\nEpoch1810  Train Loss: 0.4299  Val Loss: 0.9224  Train Acc: 0.830378 Val Acc: 0.635934\nEpoch1811  Train Loss: 0.4310  Val Loss: 1.2441  Train Acc: 0.833924 Val Acc: 0.468085\nEpoch1812  Train Loss: 0.3728  Val Loss: 1.0329  Train Acc: 0.852837 Val Acc: 0.605201\nEpoch1813  Train Loss: 0.3830  Val Loss: 1.1250  Train Acc: 0.861702 Val Acc: 0.543735\nEpoch1814  Train Loss: 0.3927  Val Loss: 1.0630  Train Acc: 0.850473 Val Acc: 0.569740\nEpoch1815  Train Loss: 0.3758  Val Loss: 1.1192  Train Acc: 0.859338 Val Acc: 0.546099\nEpoch1816  Train Loss: 0.4017  Val Loss: 0.9840  Train Acc: 0.843381 Val Acc: 0.593381\nEpoch1817  Train Loss: 0.3812  Val Loss: 1.0162  Train Acc: 0.849882 Val Acc: 0.591017\nEpoch1818  Train Loss: 0.3869  Val Loss: 1.2180  Train Acc: 0.856974 Val Acc: 0.508274\nEpoch1819  Train Loss: 0.3752  Val Loss: 1.1991  Train Acc: 0.858156 Val Acc: 0.520095\nEpoch1820  Train Loss: 0.3851  Val Loss: 1.0396  Train Acc: 0.861702 Val Acc: 0.593381\nEpoch1821  Train Loss: 0.4043  Val Loss: 1.1830  Train Acc: 0.847518 Val Acc: 0.508274\nEpoch1822  Train Loss: 0.3979  Val Loss: 0.9997  Train Acc: 0.852837 Val Acc: 0.605201\nEpoch1823  Train Loss: 0.3832  Val Loss: 1.0668  Train Acc: 0.850473 Val Acc: 0.579196\nEpoch1824  Train Loss: 0.3744  Val Loss: 1.0347  Train Acc: 0.855792 Val Acc: 0.588652\nEpoch1825  Train Loss: 0.3513  Val Loss: 1.1622  Train Acc: 0.859338 Val Acc: 0.510638\nEpoch1826  Train Loss: 0.3888  Val Loss: 1.1996  Train Acc: 0.859338 Val Acc: 0.505910\nEpoch1827  Train Loss: 0.3691  Val Loss: 1.2017  Train Acc: 0.864066 Val Acc: 0.505910\nEpoch1828  Train Loss: 0.3775  Val Loss: 1.0627  Train Acc: 0.852246 Val Acc: 0.569740\nEpoch1829  Train Loss: 0.4356  Val Loss: 1.0541  Train Acc: 0.827423 Val Acc: 0.586288\nEpoch1830  Train Loss: 0.4324  Val Loss: 1.2379  Train Acc: 0.833333 Val Acc: 0.503546\nEpoch1831  Train Loss: 0.4002  Val Loss: 1.0744  Train Acc: 0.858747 Val Acc: 0.550827\nEpoch1832  Train Loss: 0.4247  Val Loss: 1.1386  Train Acc: 0.837470 Val Acc: 0.543735\nEpoch1833  Train Loss: 0.4009  Val Loss: 1.1137  Train Acc: 0.844563 Val Acc: 0.553191\nEpoch1834  Train Loss: 0.4148  Val Loss: 1.0087  Train Acc: 0.845154 Val Acc: 0.600473\nEpoch1835  Train Loss: 0.3651  Val Loss: 1.0834  Train Acc: 0.861111 Val Acc: 0.560284\nEpoch1836  Train Loss: 0.3888  Val Loss: 1.0641  Train Acc: 0.853428 Val Acc: 0.560284\nEpoch1837  Train Loss: 0.3898  Val Loss: 1.0097  Train Acc: 0.863475 Val Acc: 0.612293\nEpoch1838  Train Loss: 0.3685  Val Loss: 1.0897  Train Acc: 0.859338 Val Acc: 0.557920\nEpoch1839  Train Loss: 0.4052  Val Loss: 0.9886  Train Acc: 0.854610 Val Acc: 0.602837\nEpoch1840  Train Loss: 0.3964  Val Loss: 1.1098  Train Acc: 0.858156 Val Acc: 0.555556\nEpoch1841  Train Loss: 0.3783  Val Loss: 1.2291  Train Acc: 0.855201 Val Acc: 0.510638\nEpoch1842  Train Loss: 0.4163  Val Loss: 1.1249  Train Acc: 0.841608 Val Acc: 0.536643\nEpoch1843  Train Loss: 0.3520  Val Loss: 1.0861  Train Acc: 0.861702 Val Acc: 0.539007\nEpoch1844  Train Loss: 0.3799  Val Loss: 0.9615  Train Acc: 0.852837 Val Acc: 0.645390\nEpoch1845  Train Loss: 0.4183  Val Loss: 1.1553  Train Acc: 0.844563 Val Acc: 0.524823\nEpoch1846  Train Loss: 0.3821  Val Loss: 1.0236  Train Acc: 0.861111 Val Acc: 0.569740\nEpoch1847  Train Loss: 0.3918  Val Loss: 1.0778  Train Acc: 0.851655 Val Acc: 0.548463\nEpoch1848  Train Loss: 0.3841  Val Loss: 1.0762  Train Acc: 0.858156 Val Acc: 0.553191\nEpoch1849  Train Loss: 0.3965  Val Loss: 1.0373  Train Acc: 0.848109 Val Acc: 0.586288\nEpoch1850  Train Loss: 0.3855  Val Loss: 1.0553  Train Acc: 0.846336 Val Acc: 0.583924\nEpoch1851  Train Loss: 0.3803  Val Loss: 1.0333  Train Acc: 0.856974 Val Acc: 0.565012\nEpoch1852  Train Loss: 0.3689  Val Loss: 1.0762  Train Acc: 0.860520 Val Acc: 0.555556\nEpoch1853  Train Loss: 0.3930  Val Loss: 0.9585  Train Acc: 0.850473 Val Acc: 0.609929\nEpoch1854  Train Loss: 0.3420  Val Loss: 1.2223  Train Acc: 0.868203 Val Acc: 0.470449\nEpoch1855  Train Loss: 0.4029  Val Loss: 1.1358  Train Acc: 0.849291 Val Acc: 0.524823\nEpoch1856  Train Loss: 0.4397  Val Loss: 1.2904  Train Acc: 0.831560 Val Acc: 0.470449\nEpoch1857  Train Loss: 0.4214  Val Loss: 1.0616  Train Acc: 0.838652 Val Acc: 0.572104\nEpoch1858  Train Loss: 0.3948  Val Loss: 1.0996  Train Acc: 0.849291 Val Acc: 0.529551\nEpoch1859  Train Loss: 0.3478  Val Loss: 1.1840  Train Acc: 0.872931 Val Acc: 0.503546\nEpoch1860  Train Loss: 0.3539  Val Loss: 1.1211  Train Acc: 0.865248 Val Acc: 0.531915\nEpoch1861  Train Loss: 0.3704  Val Loss: 1.0338  Train Acc: 0.855792 Val Acc: 0.567376\nEpoch1862  Train Loss: 0.4034  Val Loss: 1.1480  Train Acc: 0.842199 Val Acc: 0.522459\nEpoch1863  Train Loss: 0.3942  Val Loss: 1.1790  Train Acc: 0.847518 Val Acc: 0.529551\nEpoch1864  Train Loss: 0.3755  Val Loss: 1.1019  Train Acc: 0.852837 Val Acc: 0.534279\nEpoch1865  Train Loss: 0.3638  Val Loss: 1.1655  Train Acc: 0.865839 Val Acc: 0.550827\nEpoch1866  Train Loss: 0.3614  Val Loss: 1.4622  Train Acc: 0.867612 Val Acc: 0.390071\nEpoch1867  Train Loss: 0.3558  Val Loss: 1.1528  Train Acc: 0.865839 Val Acc: 0.520095\nEpoch1868  Train Loss: 0.3860  Val Loss: 1.0422  Train Acc: 0.850473 Val Acc: 0.581560\nEpoch1869  Train Loss: 0.4222  Val Loss: 1.2416  Train Acc: 0.846927 Val Acc: 0.498818\nEpoch1870  Train Loss: 0.4000  Val Loss: 1.1418  Train Acc: 0.849291 Val Acc: 0.529551\nEpoch1871  Train Loss: 0.3844  Val Loss: 1.0807  Train Acc: 0.848700 Val Acc: 0.543735\nEpoch1872  Train Loss: 0.3968  Val Loss: 1.2425  Train Acc: 0.852246 Val Acc: 0.498818\nEpoch1873  Train Loss: 0.3737  Val Loss: 0.9195  Train Acc: 0.858156 Val Acc: 0.638298\nEpoch1874  Train Loss: 0.3898  Val Loss: 1.1207  Train Acc: 0.851655 Val Acc: 0.527187\nEpoch1875  Train Loss: 0.3583  Val Loss: 1.3752  Train Acc: 0.862293 Val Acc: 0.425532\nEpoch1876  Train Loss: 0.3479  Val Loss: 1.1507  Train Acc: 0.871158 Val Acc: 0.534279\nEpoch1877  Train Loss: 0.3631  Val Loss: 1.1755  Train Acc: 0.858747 Val Acc: 0.517730\nEpoch1878  Train Loss: 0.3825  Val Loss: 1.0935  Train Acc: 0.856974 Val Acc: 0.562648\nEpoch1879  Train Loss: 0.3934  Val Loss: 1.4788  Train Acc: 0.840426 Val Acc: 0.423168\nEpoch1880  Train Loss: 0.3817  Val Loss: 1.1519  Train Acc: 0.855201 Val Acc: 0.536643\nEpoch1881  Train Loss: 0.3407  Val Loss: 1.0043  Train Acc: 0.874704 Val Acc: 0.607565\nEpoch1882  Train Loss: 0.3605  Val Loss: 1.3291  Train Acc: 0.859338 Val Acc: 0.470449\nEpoch1883  Train Loss: 0.3978  Val Loss: 1.2507  Train Acc: 0.839835 Val Acc: 0.491726\nEpoch1884  Train Loss: 0.3956  Val Loss: 1.1327  Train Acc: 0.852837 Val Acc: 0.522459\nEpoch1885  Train Loss: 0.3902  Val Loss: 1.1203  Train Acc: 0.854610 Val Acc: 0.534279\nEpoch1886  Train Loss: 0.3725  Val Loss: 1.2456  Train Acc: 0.856383 Val Acc: 0.479905\nEpoch1887  Train Loss: 0.3978  Val Loss: 1.0490  Train Acc: 0.848109 Val Acc: 0.581560\nEpoch1888  Train Loss: 0.3627  Val Loss: 1.2020  Train Acc: 0.865248 Val Acc: 0.486998\nEpoch1889  Train Loss: 0.3951  Val Loss: 1.1608  Train Acc: 0.855201 Val Acc: 0.517730\nEpoch1890  Train Loss: 0.3869  Val Loss: 1.1413  Train Acc: 0.859338 Val Acc: 0.546099\nEpoch1891  Train Loss: 0.3689  Val Loss: 1.0681  Train Acc: 0.859338 Val Acc: 0.581560\nEpoch1892  Train Loss: 0.3979  Val Loss: 1.2599  Train Acc: 0.855201 Val Acc: 0.505910\nEpoch1893  Train Loss: 0.3572  Val Loss: 1.1594  Train Acc: 0.874113 Val Acc: 0.536643\nEpoch1894  Train Loss: 0.3911  Val Loss: 1.0834  Train Acc: 0.849291 Val Acc: 0.572104\nEpoch1895  Train Loss: 0.3815  Val Loss: 1.1368  Train Acc: 0.858156 Val Acc: 0.527187\nEpoch1896  Train Loss: 0.3544  Val Loss: 1.0967  Train Acc: 0.867612 Val Acc: 0.539007\nEpoch1897  Train Loss: 0.3574  Val Loss: 1.3557  Train Acc: 0.862293 Val Acc: 0.449173\nEpoch1898  Train Loss: 0.3883  Val Loss: 1.0592  Train Acc: 0.847518 Val Acc: 0.565012\nEpoch1899  Train Loss: 0.3566  Val Loss: 1.1935  Train Acc: 0.871749 Val Acc: 0.524823\nEpoch1900  Train Loss: 0.3582  Val Loss: 1.1425  Train Acc: 0.863475 Val Acc: 0.539007\nEpoch1901  Train Loss: 0.3671  Val Loss: 1.1397  Train Acc: 0.854610 Val Acc: 0.548463\nEpoch1902  Train Loss: 0.3888  Val Loss: 1.1456  Train Acc: 0.849882 Val Acc: 0.517730\nEpoch1903  Train Loss: 0.3874  Val Loss: 1.2306  Train Acc: 0.857565 Val Acc: 0.505910\nEpoch1904  Train Loss: 0.3848  Val Loss: 1.3724  Train Acc: 0.857565 Val Acc: 0.439716\nEpoch1905  Train Loss: 0.4051  Val Loss: 1.1599  Train Acc: 0.835697 Val Acc: 0.513002\nEpoch1906  Train Loss: 0.4112  Val Loss: 1.2237  Train Acc: 0.838061 Val Acc: 0.505910\nEpoch1907  Train Loss: 0.3840  Val Loss: 1.3114  Train Acc: 0.859929 Val Acc: 0.465721\nEpoch1908  Train Loss: 0.4038  Val Loss: 1.0520  Train Acc: 0.844563 Val Acc: 0.562648\nEpoch1909  Train Loss: 0.3743  Val Loss: 1.0109  Train Acc: 0.855792 Val Acc: 0.600473\nEpoch1910  Train Loss: 0.3594  Val Loss: 1.0465  Train Acc: 0.858747 Val Acc: 0.572104\nEpoch1911  Train Loss: 0.3668  Val Loss: 1.0100  Train Acc: 0.854610 Val Acc: 0.583924\nEpoch1912  Train Loss: 0.3740  Val Loss: 1.1653  Train Acc: 0.857565 Val Acc: 0.515366\nEpoch1913  Train Loss: 0.4020  Val Loss: 1.2170  Train Acc: 0.841017 Val Acc: 0.498818\nEpoch1914  Train Loss: 0.3851  Val Loss: 1.0242  Train Acc: 0.858156 Val Acc: 0.576832\nEpoch1915  Train Loss: 0.3903  Val Loss: 1.0827  Train Acc: 0.851064 Val Acc: 0.565012\nEpoch1916  Train Loss: 0.3897  Val Loss: 1.0946  Train Acc: 0.864066 Val Acc: 0.550827\nEpoch1917  Train Loss: 0.3404  Val Loss: 1.0483  Train Acc: 0.873522 Val Acc: 0.560284\nEpoch1918  Train Loss: 0.3509  Val Loss: 1.0899  Train Acc: 0.868203 Val Acc: 0.553191\nEpoch1919  Train Loss: 0.3515  Val Loss: 1.0823  Train Acc: 0.875887 Val Acc: 0.548463\nEpoch1920  Train Loss: 0.3690  Val Loss: 1.1534  Train Acc: 0.858747 Val Acc: 0.531915\nEpoch1921  Train Loss: 0.3499  Val Loss: 1.2875  Train Acc: 0.865248 Val Acc: 0.477541\nEpoch1922  Train Loss: 0.3686  Val Loss: 1.1299  Train Acc: 0.861702 Val Acc: 0.524823\nEpoch1923  Train Loss: 0.3674  Val Loss: 1.1159  Train Acc: 0.864657 Val Acc: 0.531915\nEpoch1924  Train Loss: 0.3561  Val Loss: 1.0903  Train Acc: 0.858747 Val Acc: 0.541371\nEpoch1925  Train Loss: 0.3531  Val Loss: 1.1697  Train Acc: 0.872931 Val Acc: 0.520095\nEpoch1926  Train Loss: 0.3757  Val Loss: 1.1431  Train Acc: 0.854610 Val Acc: 0.515366\nEpoch1927  Train Loss: 0.3952  Val Loss: 1.0395  Train Acc: 0.855792 Val Acc: 0.586288\nEpoch1928  Train Loss: 0.3482  Val Loss: 1.1072  Train Acc: 0.879433 Val Acc: 0.531915\nEpoch1929  Train Loss: 0.3546  Val Loss: 1.1112  Train Acc: 0.867612 Val Acc: 0.546099\nEpoch1930  Train Loss: 0.3894  Val Loss: 1.1879  Train Acc: 0.857565 Val Acc: 0.501182\nEpoch1931  Train Loss: 0.3812  Val Loss: 1.1837  Train Acc: 0.848109 Val Acc: 0.484634\nEpoch1932  Train Loss: 0.4279  Val Loss: 1.1721  Train Acc: 0.832742 Val Acc: 0.517730\nEpoch1933  Train Loss: 0.3594  Val Loss: 1.5747  Train Acc: 0.867612 Val Acc: 0.387707\nEpoch1934  Train Loss: 0.4163  Val Loss: 1.0943  Train Acc: 0.841017 Val Acc: 0.560284\nEpoch1935  Train Loss: 0.4013  Val Loss: 1.1269  Train Acc: 0.842199 Val Acc: 0.546099\nEpoch1936  Train Loss: 0.4035  Val Loss: 1.2805  Train Acc: 0.845154 Val Acc: 0.470449\nEpoch1937  Train Loss: 0.3952  Val Loss: 1.0245  Train Acc: 0.851064 Val Acc: 0.583924\nEpoch1938  Train Loss: 0.3938  Val Loss: 0.9636  Train Acc: 0.852837 Val Acc: 0.619385\nEpoch1939  Train Loss: 0.3912  Val Loss: 1.1200  Train Acc: 0.858747 Val Acc: 0.546099\nEpoch1940  Train Loss: 0.3620  Val Loss: 1.0401  Train Acc: 0.867612 Val Acc: 0.581560\nEpoch1941  Train Loss: 0.3806  Val Loss: 1.0044  Train Acc: 0.855201 Val Acc: 0.607565\nEpoch1942  Train Loss: 0.3683  Val Loss: 1.0178  Train Acc: 0.867021 Val Acc: 0.572104\nEpoch1943  Train Loss: 0.3584  Val Loss: 1.0652  Train Acc: 0.862293 Val Acc: 0.567376\nEpoch1944  Train Loss: 0.3676  Val Loss: 1.0304  Train Acc: 0.863475 Val Acc: 0.574468\nEpoch1945  Train Loss: 0.3661  Val Loss: 1.0658  Train Acc: 0.856974 Val Acc: 0.565012\nEpoch1946  Train Loss: 0.3942  Val Loss: 1.0409  Train Acc: 0.854019 Val Acc: 0.583924\nEpoch1947  Train Loss: 0.3972  Val Loss: 1.1722  Train Acc: 0.848700 Val Acc: 0.513002\nEpoch1948  Train Loss: 0.3718  Val Loss: 1.1440  Train Acc: 0.865839 Val Acc: 0.510638\nEpoch1949  Train Loss: 0.3643  Val Loss: 1.1407  Train Acc: 0.858156 Val Acc: 0.529551\nEpoch1950  Train Loss: 0.3677  Val Loss: 1.2702  Train Acc: 0.861702 Val Acc: 0.477541\nEpoch1951  Train Loss: 0.3777  Val Loss: 1.2063  Train Acc: 0.861702 Val Acc: 0.505910\nEpoch1952  Train Loss: 0.3528  Val Loss: 1.1358  Train Acc: 0.862884 Val Acc: 0.527187\nEpoch1953  Train Loss: 0.3689  Val Loss: 1.0792  Train Acc: 0.860520 Val Acc: 0.555556\nEpoch1954  Train Loss: 0.3799  Val Loss: 1.2533  Train Acc: 0.845154 Val Acc: 0.491726\nEpoch1955  Train Loss: 0.4186  Val Loss: 1.3901  Train Acc: 0.835697 Val Acc: 0.463357\nEpoch1956  Train Loss: 0.4165  Val Loss: 1.2228  Train Acc: 0.843972 Val Acc: 0.494090\nEpoch1957  Train Loss: 0.3846  Val Loss: 1.1813  Train Acc: 0.853428 Val Acc: 0.498818\nEpoch1958  Train Loss: 0.3648  Val Loss: 1.2817  Train Acc: 0.856974 Val Acc: 0.479905\nEpoch1959  Train Loss: 0.3682  Val Loss: 1.2299  Train Acc: 0.859929 Val Acc: 0.501182\nEpoch1960  Train Loss: 0.3699  Val Loss: 1.2809  Train Acc: 0.855201 Val Acc: 0.482270\nEpoch1961  Train Loss: 0.3838  Val Loss: 1.3083  Train Acc: 0.857565 Val Acc: 0.460993\nEpoch1962  Train Loss: 0.3545  Val Loss: 1.0862  Train Acc: 0.867021 Val Acc: 0.539007\nEpoch1963  Train Loss: 0.3790  Val Loss: 1.2600  Train Acc: 0.861111 Val Acc: 0.489362\nEpoch1964  Train Loss: 0.3734  Val Loss: 1.0254  Train Acc: 0.861111 Val Acc: 0.593381\nEpoch1965  Train Loss: 0.3650  Val Loss: 1.1816  Train Acc: 0.870567 Val Acc: 0.524823\nEpoch1966  Train Loss: 0.4163  Val Loss: 1.1271  Train Acc: 0.842199 Val Acc: 0.522459\nEpoch1967  Train Loss: 0.4107  Val Loss: 1.1623  Train Acc: 0.846336 Val Acc: 0.531915\nEpoch1968  Train Loss: 0.3608  Val Loss: 1.3337  Train Acc: 0.868794 Val Acc: 0.446809\nEpoch1969  Train Loss: 0.3850  Val Loss: 1.1910  Train Acc: 0.860520 Val Acc: 0.496454\nEpoch1970  Train Loss: 0.3832  Val Loss: 1.1585  Train Acc: 0.857565 Val Acc: 0.510638\nEpoch1971  Train Loss: 0.3823  Val Loss: 1.1234  Train Acc: 0.858156 Val Acc: 0.524823\nEpoch1972  Train Loss: 0.3629  Val Loss: 1.1772  Train Acc: 0.864066 Val Acc: 0.520095\nEpoch1973  Train Loss: 0.3880  Val Loss: 1.0764  Train Acc: 0.848700 Val Acc: 0.565012\nEpoch1974  Train Loss: 0.3976  Val Loss: 1.2133  Train Acc: 0.850473 Val Acc: 0.510638\nEpoch1975  Train Loss: 0.3754  Val Loss: 1.3129  Train Acc: 0.861111 Val Acc: 0.458629\nEpoch1976  Train Loss: 0.3596  Val Loss: 1.1746  Train Acc: 0.862884 Val Acc: 0.501182\nEpoch1977  Train Loss: 0.3316  Val Loss: 1.1389  Train Acc: 0.882388 Val Acc: 0.541371\nEpoch1978  Train Loss: 0.3605  Val Loss: 1.2740  Train Acc: 0.862884 Val Acc: 0.475177\nEpoch1979  Train Loss: 0.3837  Val Loss: 1.1691  Train Acc: 0.852246 Val Acc: 0.539007\nEpoch1980  Train Loss: 0.3723  Val Loss: 1.3880  Train Acc: 0.851655 Val Acc: 0.456265\nEpoch1981  Train Loss: 0.3787  Val Loss: 1.1874  Train Acc: 0.853428 Val Acc: 0.527187\nEpoch1982  Train Loss: 0.3793  Val Loss: 1.0973  Train Acc: 0.851064 Val Acc: 0.562648\nEpoch1983  Train Loss: 0.3662  Val Loss: 1.2189  Train Acc: 0.869976 Val Acc: 0.494090\nEpoch1984  Train Loss: 0.3926  Val Loss: 1.2043  Train Acc: 0.843381 Val Acc: 0.515366\nEpoch1985  Train Loss: 0.3610  Val Loss: 1.1926  Train Acc: 0.859338 Val Acc: 0.527187\nEpoch1986  Train Loss: 0.3588  Val Loss: 1.2077  Train Acc: 0.864066 Val Acc: 0.517730\nEpoch1987  Train Loss: 0.3769  Val Loss: 1.3660  Train Acc: 0.856383 Val Acc: 0.479905\nEpoch1988  Train Loss: 0.3819  Val Loss: 1.2506  Train Acc: 0.864066 Val Acc: 0.501182\nEpoch1989  Train Loss: 0.3661  Val Loss: 1.4199  Train Acc: 0.862293 Val Acc: 0.430260\nEpoch1990  Train Loss: 0.4123  Val Loss: 1.1053  Train Acc: 0.841017 Val Acc: 0.550827\nEpoch1991  Train Loss: 0.3986  Val Loss: 1.2710  Train Acc: 0.846336 Val Acc: 0.472813\nEpoch1992  Train Loss: 0.3910  Val Loss: 1.3136  Train Acc: 0.841017 Val Acc: 0.494090\nEpoch1993  Train Loss: 0.3956  Val Loss: 1.0836  Train Acc: 0.846927 Val Acc: 0.567376\nEpoch1994  Train Loss: 0.3656  Val Loss: 1.4974  Train Acc: 0.857565 Val Acc: 0.401891\nEpoch1995  Train Loss: 0.3707  Val Loss: 1.1813  Train Acc: 0.853428 Val Acc: 0.524823\nEpoch1996  Train Loss: 0.3790  Val Loss: 1.0616  Train Acc: 0.853428 Val Acc: 0.579196\nEpoch1997  Train Loss: 0.3704  Val Loss: 1.2020  Train Acc: 0.861702 Val Acc: 0.505910\nEpoch1998  Train Loss: 0.3709  Val Loss: 1.1290  Train Acc: 0.862884 Val Acc: 0.531915\nEpoch1999  Train Loss: 0.3850  Val Loss: 1.3934  Train Acc: 0.859338 Val Acc: 0.427896\nEpoch2000  Train Loss: 0.4015  Val Loss: 1.1035  Train Acc: 0.845745 Val Acc: 0.524823\n"
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 2000\n",
    "\n",
    "#valid_loss_min = 0.784589\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    train_correct, train_total = 0, 0\n",
    "    for data, target in train_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        #print(target.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        train_total += len(target)\n",
    "        train_correct += (predicted == target).sum().item()\n",
    "    train_acc = train_correct/train_total\n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    val_correct, val_total = 0, 0\n",
    "    for data, target in valid_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        val_total += len(target)\n",
    "        val_correct += (predicted == target).sum().item()\n",
    "    val_acc = val_correct/val_total\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch{}  Train Loss: {:.4f}  Val Loss: {:.4f}  Train Acc: {:.6f} Val Acc: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss, train_acc, val_acc))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if val_acc >= val_acc_max:\n",
    "        print('Validation acc increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        val_acc_max,\n",
    "        val_acc))\n",
    "        torch.save(model.state_dict(), 'model_EEG.pt')\n",
    "        val_acc_max = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Lowest Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_EEG.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bfa8e9857a03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "test_data = data.TensorDataset(X_test, y_test)\n",
    "\n",
    "test_loader = data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Test Loss: 0.968028\n\nTest Accuracy of   769: 37% (42/111)\nTest Accuracy of   770: 77% (98/127)\nTest Accuracy of   771: 71% (69/96)\nTest Accuracy of   772: 55% (61/109)\n\nTest Accuracy (Overall): 60% (270/443)\n"
    }
   ],
   "source": [
    "# specify the target classes\n",
    "classes = [769, 770, 771, 772]\n",
    "\n",
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "\n",
    "model.eval()\n",
    "for data, target in test_loader:\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    #print(pred)\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(correct.shape[0]):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(4):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}